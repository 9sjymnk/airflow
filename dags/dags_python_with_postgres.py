import pendulum
from hooks.custom_postgres_hook import CustomPostgresHook

# Airflow 3.0 ë¶€í„° ì•„ë˜ ê²½ë¡œë¡œ import í•©ë‹ˆë‹¤.
from airflow.sdk import DAG
from airflow.providers.standard.operators.python import PythonOperator

# Airflow 2.10.5 ì´í•˜ ë²„ì „ì—ì„œ ì‹¤ìŠµì‹œ ì•„ë˜ ê²½ë¡œì—ì„œ import í•˜ì„¸ìš”.
# from airflow import DAG
# from airflow.operators.python import PythonOperator

with DAG(
    dag_id='dags_python_with_custom_hook_bulk_load',
    start_date=pendulum.datetime(2023, 4, 1, tz='Asia/Seoul'),
    schedule='0 7 * * *',   # ë§¤ì¼ 07:00 ì‹¤í–‰
    catchup=False
) as dag:

    def insrt_postgres(postgres_conn_id, tbl_nm, file_nm, **kwargs):
        custom_postgres_hook = CustomPostgresHook(postgres_conn_id=postgres_conn_id)
        custom_postgres_hook.bulk_load(
            table_name=tbl_nm,
            file_name=file_nm,
            delimiter='\t',          # ğŸ”‘ CSVê°€ íƒ­ êµ¬ë¶„ìë¼ì„œ ê¼­ \t ë¡œ ì„¤ì •
            is_header=True,
            is_replace=True
        )

    insrt_postgres = PythonOperator(
        task_id='insrt_postgres',
        python_callable=insrt_postgres,
        op_kwargs={
            'postgres_conn_id': 'conn-db-postgres-custom',
            'tbl_nm': 'TbCorona19CountStatus_bulk2',
            'file_nm': '/opt/airflow/files/TbCorona19CountStatus/{{data_interval_end.in_timezone("Asia/Seoul") | ds_nodash}}/TbCorona19CountStatus.csv'
        }
    )
